{"cells":[{"cell_type":"markdown","id":"8a5706df","metadata":{"id":"8a5706df"},"source":["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/evaluation/retrieval/retriever_eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","id":"36129c05-81f2-466c-a507-b62a577199d8","metadata":{"id":"36129c05-81f2-466c-a507-b62a577199d8"},"source":["# Retrieval Evaluation\n","\n","This notebook uses our `RetrieverEvaluator` to evaluate the quality of any Retriever module defined in LlamaIndex.\n","\n","We specify a set of different evaluation metrics: this includes hit-rate and MRR. For any given question, these will compare the quality of retrieved results from the ground-truth context.\n","\n","To ease the burden of creating the eval dataset in the first place, we can rely on synthetic data generation."]},{"cell_type":"markdown","id":"8659681a-7141-4f80-9bbe-8eddc061a134","metadata":{"id":"8659681a-7141-4f80-9bbe-8eddc061a134"},"source":["## Setup\n","\n","Here we load in data (PG essay), parse into Nodes. We then index this data using our simple vector index and get a retriever."]},{"cell_type":"code","execution_count":null,"id":"9df86266","metadata":{"id":"9df86266","executionInfo":{"status":"ok","timestamp":1717486789929,"user_tz":-180,"elapsed":17824,"user":{"displayName":"","userId":""}},"outputId":"5463d663-771e-4f4d-ae8c-6c66bc43d52b","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting llama-index-llms-openai\n","  Downloading llama_index_llms_openai-0.1.22-py3-none-any.whl (11 kB)\n","Collecting llama-index-core<0.11.0,>=0.10.24 (from llama-index-llms-openai)\n","  Downloading llama_index_core-0.10.43-py3-none-any.whl (15.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (6.0.1)\n","Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.0.30)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.9.5)\n","Collecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai)\n","  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n","Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai)\n","  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n","Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai)\n","  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2023.6.0)\n","Collecting httpx (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai)\n","  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting llamaindex-py-client<0.2.0,>=0.1.18 (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai)\n","  Downloading llamaindex_py_client-0.1.19-py3-none-any.whl (141 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.6.0)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.3)\n","Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.25.2)\n","Collecting openai>=1.1.0 (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai)\n","  Downloading openai-1.31.0-py3-none-any.whl (324 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.1/324.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.0.3)\n","Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (9.4.0)\n","Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (8.3.0)\n","Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai)\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (4.66.4)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (4.12.0)\n","Collecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.14.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (4.0.3)\n","Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.7.2)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.2.2)\n","Collecting httpcore==1.* (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai)\n","  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.3.1)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.5.15)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.7.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.0.7)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.0.3)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai)\n","  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m537.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.2.1)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (24.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.18.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.18.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.16.0)\n","Installing collected packages: dirtyjson, mypy-extensions, marshmallow, h11, deprecated, typing-inspect, tiktoken, httpcore, httpx, dataclasses-json, openai, llamaindex-py-client, llama-index-core, llama-index-llms-openai\n","Successfully installed dataclasses-json-0.6.6 deprecated-1.2.14 dirtyjson-1.0.8 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 llama-index-core-0.10.43 llama-index-llms-openai-0.1.22 llamaindex-py-client-0.1.19 marshmallow-3.21.2 mypy-extensions-1.0.0 openai-1.31.0 tiktoken-0.7.0 typing-inspect-0.9.0\n"]}],"source":["%pip install llama-index-llms-openai"]},{"cell_type":"code","execution_count":null,"id":"bb6fecf4-7215-4ae9-b02b-3cb7c6000f2c","metadata":{"id":"bb6fecf4-7215-4ae9-b02b-3cb7c6000f2c"},"outputs":[],"source":["import nest_asyncio\n","\n","nest_asyncio.apply()"]},{"cell_type":"code","execution_count":null,"id":"4f63b16c-6a83-4ef0-a451-43c2c3d9c828","metadata":{"id":"4f63b16c-6a83-4ef0-a451-43c2c3d9c828"},"outputs":[],"source":["from llama_index.core.evaluation import generate_question_context_pairs\n","from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n","from llama_index.core.node_parser import SentenceSplitter\n","from llama_index.llms.openai import OpenAI"]},{"cell_type":"markdown","id":"4e3b3f28","metadata":{"id":"4e3b3f28"},"source":["Download Data"]},{"cell_type":"code","execution_count":null,"id":"589c112d","metadata":{"id":"589c112d","executionInfo":{"status":"ok","timestamp":1717486822173,"user_tz":-180,"elapsed":485,"user":{"displayName":"","userId":""}},"outputId":"8ea9269e-e518-45ea-c17b-c0c2006308a5","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-06-04 07:40:21--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 75042 (73K) [text/plain]\n","Saving to: ‘data/paul_graham/paul_graham_essay.txt’\n","\n","\r          data/paul   0%[                    ]       0  --.-KB/s               \rdata/paul_graham/pa 100%[===================>]  73.28K  --.-KB/s    in 0.02s   \n","\n","2024-06-04 07:40:21 (3.29 MB/s) - ‘data/paul_graham/paul_graham_essay.txt’ saved [75042/75042]\n","\n"]}],"source":["!mkdir -p 'data/paul_graham/'\n","!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"]},{"cell_type":"code","execution_count":null,"id":"ab50ac91-e9d4-4fae-a519-db5711a13210","metadata":{"id":"ab50ac91-e9d4-4fae-a519-db5711a13210"},"outputs":[],"source":["documents = SimpleDirectoryReader(\"./data/\").load_data()"]},{"cell_type":"code","source":["documents"],"metadata":{"id":"4UxmgYFoP_2m","executionInfo":{"status":"ok","timestamp":1717487803276,"user_tz":-180,"elapsed":15,"user":{"displayName":"","userId":""}},"outputId":"2369506a-a306-456b-f516-958c7437350a","colab":{"base_uri":"https://localhost:8080/"}},"id":"4UxmgYFoP_2m","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Document(id_='88184ed5-aefc-4f27-a514-2ec98881f45e', embedding=None, metadata={'file_path': '/content/data/test.txt', 'file_name': 'test.txt', 'file_type': 'text/plain', 'file_size': 6427, 'creation_date': '2024-06-04', 'last_modified_date': '2024-06-04'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='L informatique est une discipline scientifique et technique qui traite de l etude  de la conception  du developpement  de la gestion et de l utilisation des systemes d information et des logiciels  Ce domaine englobe un large eventail de sous disciplines  allant de la programmation et de l algorithmique a l intelligence artificielle  en passant par les bases de donnees  les reseaux  la securite informatique et l ingenierie logicielle  L informatique joue un role crucial dans la societe moderne  influencant divers aspects de notre vie quotidienne  des communications et du divertissement a la sante et a l education \\n\\nHistorique de l informatique\\nL histoire de l informatique remonte a plusieurs siecles  bien avant l invention des ordinateurs modernes  Les premieres tentatives de calcul automatise peuvent etre retracees a des dispositifs mecaniques tels que le boulier  invente il y a des milliers d annees  Cependant  c est au 19eme siecle que l informatique a commence a prendre forme  avec des inventions comme la machine a differences de Charles Babbage et le travail de Ada Lovelace  souvent consideree comme la premiere programmeuse informatique \\n\\nLe 20eme siecle a marque un tournant decisif avec l avenement des ordinateurs electroniques  Les travaux de pionniers comme Alan Turing  John von Neumann et Claude Shannon ont jete les bases theoriques de l informatique moderne  Le developpement des premiers ordinateurs electroniques pendant la Seconde Guerre mondiale  tels que l ENIAC  a demontre le potentiel enorme de cette technologie pour resoudre des problemes complexes \\n\\nL ere des ordinateurs personnels\\nLes annees 1970 et 1980 ont vu l emergence des ordinateurs personnels  PC   qui ont revolutionne la maniere dont les gens interagissent avec la technologie  Des entreprises comme Apple  avec son Apple II  et IBM  avec son IBM PC  ont rendu l informatique accessible a un public beaucoup plus large  Cette periode a egalement vu la naissance de logiciels emblematiques  tels que les systemes d exploitation MS DOS et Windows de Microsoft  qui ont standardise et simplifie l utilisation des ordinateurs \\n\\nReseaux et Internet\\nL avenement des reseaux informatiques et de l Internet a ete une autre revolution majeure  Initialement developpe comme un projet de recherche militaire par l ARPA  Advanced Research Projects Agency  sous le nom d ARPANET  l Internet est devenu un reseau mondial interconnectant des millions de systemes informatiques  Le developpement du protocole TCP/IP  le systeme de noms de domaine  DNS  et la creation du World Wide Web par Tim Berners Lee ont rendu Internet accessible et utile pour le grand public \\n\\nL informatique contemporaine\\nAujourd hui  l informatique est omnipresente et se manifeste sous diverses formes  Les smartphones  les tablettes  les objets connectes  IoT  et les infrastructures cloud sont autant de temoignages de l evolution rapide de la technologie informatique  Le cloud computing  en particulier  a transforme la maniere dont les entreprises et les particuliers stockent et accedent aux donnees  offrant des solutions evolutives et flexibles pour repondre a des besoins varies \\n\\nIntelligence artificielle et apprentissage automatique\\nL intelligence artificielle  IA  et l apprentissage automatique  ML  representent l une des frontieres les plus avancees de l informatique contemporaine  L IA vise a creer des systemes capables de simuler des processus cognitifs humains  tels que l apprentissage  le raisonnement et la perception  Les progres dans ce domaine ont conduit a des applications innovantes  allant des assistants virtuels comme Siri et Alexa a des systemes de recommandation personnalises sur des plateformes comme Netflix et Amazon \\n\\nL apprentissage automatique  une sous discipline de l IA  utilise des algorithmes et des modeles statistiques pour permettre aux ordinateurs de prendre des decisions basees sur des donnees  Des techniques telles que les reseaux neuronaux profonds  deep learning  ont permis des avancees significatives dans des domaines comme la reconnaissance d images  la comprehension du langage naturel et les jeux video \\n\\nSecurite informatique\\nAvec l augmentation de la dependance aux technologies numeriques  la securite informatique est devenue une preoccupation majeure  Les cyberattaques  les violations de donnees et les malwares sont des menaces constantes pour les individus  les entreprises et les gouvernements  La cybersecurite vise a proteger les systemes informatiques  les reseaux et les donnees contre les acces non autorises  les attaques et les dommages  Des pratiques telles que le chiffrement  l authentification multi facteurs et les pare feu sont essentielles pour maintenir la securite et la confidentialite des informations \\n\\nethique et informatique\\nL essor de l informatique souleve egalement des questions ethiques importantes  La collecte et l utilisation massive de donnees personnelles par les entreprises technologiques  la surveillance de masse  les biais dans les algorithmes d IA et l impact environnemental des centres de donnees sont autant de sujets de preoccupation  Il est crucial de developper des cadres ethiques et des regulations pour garantir que la technologie est utilisee de maniere responsable et benefique pour la societe \\n\\nL avenir de l informatique\\nL avenir de l informatique est prometteur et plein de defis passionnants  Les recherches en informatique quantique visent a developper des ordinateurs capables de resoudre des problemes complexes bien au dela des capacites des ordinateurs classiques  Les progres dans les interfaces cerveau ordinateur pourraient revolutionner la maniere dont les humains interagissent avec les machines  De plus  l informatique ubiquitaire  ou les dispositifs informatiques sont integres de maniere transparente dans l environnement quotidien  pourrait transformer notre maniere de vivre et de travailler \\n\\nEn conclusion  l informatique est une discipline dynamique et en constante evolution  qui continue de faconner le monde moderne  Des premiers calculateurs mecaniques aux systemes d intelligence artificielle avancee  l informatique a parcouru un long chemin et reste au coeur de nombreuses innovations technologiques  Alors que nous avancons vers un avenir de plus en plus numerique  l importance de l informatique ne fera que croitre  ouvrant de nouvelles possibilites et posant de nouveaux defis pour les generations futures \\n', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["! pip install llama_index"],"metadata":{"id":"TIypdi2vMhvP","executionInfo":{"status":"ok","timestamp":1717486909756,"user_tz":-180,"elapsed":11832,"user":{"displayName":"","userId":""}},"outputId":"939d6429-ba03-469f-c227-2afec566f1b8","colab":{"base_uri":"https://localhost:8080/"}},"id":"TIypdi2vMhvP","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting llama_index\n","  Downloading llama_index-0.10.43-py3-none-any.whl (6.8 kB)\n","Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama_index)\n","  Downloading llama_index_agent_openai-0.2.7-py3-none-any.whl (12 kB)\n","Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama_index)\n","  Downloading llama_index_cli-0.1.12-py3-none-any.whl (26 kB)\n","Requirement already satisfied: llama-index-core==0.10.43 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.10.43)\n","Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama_index)\n","  Downloading llama_index_embeddings_openai-0.1.10-py3-none-any.whl (6.2 kB)\n","Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama_index)\n","  Downloading llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl (6.7 kB)\n","Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama_index)\n","  Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.1.22)\n","Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama_index)\n","  Downloading llama_index_multi_modal_llms_openai-0.1.6-py3-none-any.whl (5.8 kB)\n","Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama_index)\n","  Downloading llama_index_program_openai-0.1.6-py3-none-any.whl (5.2 kB)\n","Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama_index)\n","  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n","Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama_index)\n","  Downloading llama_index_readers_file-0.1.23-py3-none-any.whl (36 kB)\n","Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama_index)\n","  Downloading llama_index_readers_llama_parse-0.1.4-py3-none-any.whl (2.5 kB)\n","Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama_index) (6.0.1)\n","Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama_index) (2.0.30)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama_index) (3.9.5)\n","Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama_index) (0.6.6)\n","Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama_index) (1.2.14)\n","Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama_index) (1.0.8)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama_index) (2023.6.0)\n","Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama_index) (0.27.0)\n","Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama_index) (0.1.19)\n","Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama_index) (1.6.0)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama_index) (3.3)\n","Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama_index) (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama_index) (1.25.2)\n","Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama_index) (1.31.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama_index) (2.0.3)\n","Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama_index) (9.4.0)\n","Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama_index) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama_index) (8.3.0)\n","Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama_index) (0.7.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama_index) (4.66.4)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama_index) (4.12.0)\n","Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama_index) (0.9.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama_index) (1.14.1)\n","Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama_index) (4.12.3)\n","Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama_index)\n","  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama_index)\n","  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n","Collecting llama-parse<0.5.0,>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index)\n","  Downloading llama_parse-0.4.4-py3-none-any.whl (8.0 kB)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.43->llama_index) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.43->llama_index) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.43->llama_index) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.43->llama_index) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.43->llama_index) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.43->llama_index) (4.0.3)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama_index) (2.5)\n","Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core==0.10.43->llama_index) (2.7.2)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.43->llama_index) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.43->llama_index) (2024.2.2)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.43->llama_index) (1.0.5)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.43->llama_index) (3.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.43->llama_index) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core==0.10.43->llama_index) (0.14.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.43->llama_index) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.43->llama_index) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.43->llama_index) (2024.5.15)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core==0.10.43->llama_index) (1.7.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.10.43->llama_index) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.10.43->llama_index) (2.0.7)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.43->llama_index) (3.0.3)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core==0.10.43->llama_index) (1.0.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core==0.10.43->llama_index) (3.21.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.43->llama_index) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.43->llama_index) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.43->llama_index) (2024.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core==0.10.43->llama_index) (1.2.1)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.10.43->llama_index) (24.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core==0.10.43->llama_index) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.18.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core==0.10.43->llama_index) (2.18.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core==0.10.43->llama_index) (1.16.0)\n","Installing collected packages: striprtf, pypdf, llama-index-legacy, llama-parse, llama-index-readers-file, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama_index\n","Successfully installed llama-index-agent-openai-0.2.7 llama-index-cli-0.1.12 llama-index-embeddings-openai-0.1.10 llama-index-indices-managed-llama-cloud-0.1.6 llama-index-legacy-0.9.48 llama-index-multi-modal-llms-openai-0.1.6 llama-index-program-openai-0.1.6 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.23 llama-index-readers-llama-parse-0.1.4 llama-parse-0.4.4 llama_index-0.10.43 pypdf-4.2.0 striprtf-0.0.26\n"]}]},{"cell_type":"code","execution_count":null,"id":"66499039-d76d-4914-b03a-bcbd10c8c33b","metadata":{"id":"66499039-d76d-4914-b03a-bcbd10c8c33b"},"outputs":[],"source":["node_parser = SentenceSplitter(chunk_size=512)\n","nodes = node_parser.get_nodes_from_documents(documents)"]},{"cell_type":"code","execution_count":null,"id":"af31b424-02c4-4731-beca-e88ef4f202ca","metadata":{"id":"af31b424-02c4-4731-beca-e88ef4f202ca"},"outputs":[],"source":["# by default, the node ids are set to random uuids. To ensure same id's per run, we manually set them.\n","for idx, node in enumerate(nodes):\n","    node.id_ = f\"node_{idx}\""]},{"cell_type":"code","source":["len(nodes)"],"metadata":{"id":"ixOQg6oEQJQG","executionInfo":{"status":"ok","timestamp":1717487843087,"user_tz":-180,"elapsed":15,"user":{"displayName":"","userId":""}},"outputId":"15f07e09-e73d-4e46-89a9-15fec7a84bb1","colab":{"base_uri":"https://localhost:8080/"}},"id":"ixOQg6oEQJQG","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["import os\n","os.environ[\"OPENAI_API_KEY\"] = \"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\"\n","hugging = \"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\""],"metadata":{"id":"7MC00ef8M7Od"},"id":"7MC00ef8M7Od","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"c1268ad2-3b29-49dc-92b3-6894900b4534","metadata":{"id":"c1268ad2-3b29-49dc-92b3-6894900b4534"},"outputs":[],"source":["llm = OpenAI(model=\"gpt-3.5-turbo-16k-0613\")"]},{"cell_type":"code","execution_count":null,"id":"11836d3f-136d-45fe-bad8-f0480751ee67","metadata":{"id":"11836d3f-136d-45fe-bad8-f0480751ee67"},"outputs":[],"source":["vector_index = VectorStoreIndex(nodes)\n","retriever = vector_index.as_retriever(similarity_top_k=2)"]},{"cell_type":"markdown","id":"baf75ec6-7419-4975-83df-6d6fa08adb77","metadata":{"id":"baf75ec6-7419-4975-83df-6d6fa08adb77"},"source":["### Try out Retrieval\n","\n","We'll try out retrieval over a simple dataset."]},{"cell_type":"code","execution_count":null,"id":"fd260990-0aea-490b-99e0-d7517f668020","metadata":{"id":"fd260990-0aea-490b-99e0-d7517f668020"},"outputs":[],"source":["retrieved_nodes = retriever.retrieve(\"What did the author do growing up?\")"]},{"cell_type":"code","execution_count":null,"id":"ce4b0823-8be4-4dd4-8486-8e73d79590fe","metadata":{"id":"ce4b0823-8be4-4dd4-8486-8e73d79590fe","executionInfo":{"status":"ok","timestamp":1717487019934,"user_tz":-180,"elapsed":492,"user":{"displayName":"","userId":""}},"outputId":"f641b898-3f23-464c-9648-5d9dc8031b8a","colab":{"base_uri":"https://localhost:8080/","height":494}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**Node ID:** node_0<br>**Similarity:** 0.8175155065341562<br>**Text:** What I Worked On\n\nFebruary 2021\n\nBefore college the two main things I worked on, outside of school, were writing and programming. I didn't write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\n\nThe first programs I tried writing were on the IBM 1401 that our school district used for what was then called \"data processing.\" This was in 9th grade, so I was 13 or 14. The school district's 1401 happened to be in the basement of our junior high school, and my friend Rich Draves and I got permission to use it. It was like a mini Bond villain's lair down there, with all these alien-looking machines — CPU, disk drives, printer, card reader — sitting up on a raised floor under bright fluorescent lights.\n\nThe language we used was an early version of Fortran. You had to type programs on punch cards, then stack them in ...<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**Node ID:** node_52<br>**Similarity:** 0.8114902287812894<br>**Text:** It felt like I was doing life right. I remember that because I was slightly dismayed at how novel it felt. The good news is that I had more moments like this over the next few years.\n\nIn the summer of 2016 we moved to England. We wanted our kids to see what it was like living in another country, and since I was a British citizen by birth, that seemed the obvious choice. We only meant to stay for a year, but we liked it so much that we still live there. So most of Bel was written in England.\n\nIn the fall of 2019, Bel was finally finished. Like McCarthy's original Lisp, it's a spec rather than an implementation, although like McCarthy's Lisp it's a spec expressed as code.\n\nNow that I could write essays again, I wrote a bunch about topics I'd had stacked up. I kept writing essays through 2020, but I also started to think about other things I could work on. How should I choose what to do? Well, how had I chosen what to work on in the past? I wrote an essay for myself to answer that ques...<br>"},"metadata":{}}],"source":["from llama_index.core.response.notebook_utils import display_source_node\n","\n","for node in retrieved_nodes:\n","    display_source_node(node, source_length=1000)"]},{"cell_type":"markdown","id":"5371db56-2b1c-497a-8fd0-a1a69b2ce773","metadata":{"id":"5371db56-2b1c-497a-8fd0-a1a69b2ce773"},"source":["## Build an Evaluation dataset of (query, context) pairs\n","\n","Here we build a simple evaluation dataset over the existing text corpus.\n","\n","We use our `generate_question_context_pairs` to generate a set of (question, context) pairs over a given unstructured text corpus. This uses the LLM to auto-generate questions from each context chunk.\n","\n","We get back a `EmbeddingQAFinetuneDataset` object. At a high-level this contains a set of ids mapping to queries and relevant doc chunks, as well as the corpus itself."]},{"cell_type":"code","execution_count":null,"id":"a25924cf-7eeb-4160-a035-4a69ee1e46de","metadata":{"id":"a25924cf-7eeb-4160-a035-4a69ee1e46de"},"outputs":[],"source":["from llama_index.core.evaluation import (\n","    generate_question_context_pairs,\n","    EmbeddingQAFinetuneDataset,\n",")"]},{"cell_type":"code","execution_count":null,"id":"2d29a159-9a4f-4d44-9c0d-1cd683f8bb9b","metadata":{"id":"2d29a159-9a4f-4d44-9c0d-1cd683f8bb9b","executionInfo":{"status":"ok","timestamp":1717487933522,"user_tz":-180,"elapsed":55705,"user":{"displayName":"","userId":""}},"outputId":"d62bb4b9-c5c1-476a-d423-6dbd9f4747b1","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5/5 [00:55<00:00, 11.05s/it]\n"]}],"source":["qa_dataset = generate_question_context_pairs(\n","    nodes, llm=llm, num_questions_per_chunk=2\n",")"]},{"cell_type":"code","execution_count":null,"id":"f32d458b-50ad-426c-a969-e9fe8fb5861a","metadata":{"id":"f32d458b-50ad-426c-a969-e9fe8fb5861a","executionInfo":{"status":"ok","timestamp":1717487940419,"user_tz":-180,"elapsed":445,"user":{"displayName":"","userId":""}},"outputId":"86b4f9d3-2f0c-4ade-f48c-2023e3e2100d","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["How did the development of early electronic computers during World War II, such as the ENIAC, demonstrate the potential of this technology?\n"]}],"source":["queries = qa_dataset.queries.values()\n","print(list(queries)[2])"]},{"cell_type":"code","execution_count":null,"id":"6a900650-38ed-405e-936c-08e48e0fb8ea","metadata":{"id":"6a900650-38ed-405e-936c-08e48e0fb8ea"},"outputs":[],"source":["# [optional] save\n","qa_dataset.save_json(\"pg_eval_dataset.json\")"]},{"cell_type":"code","execution_count":null,"id":"713c1b71-2ab6-42a0-bde3-ab3bfe880f97","metadata":{"id":"713c1b71-2ab6-42a0-bde3-ab3bfe880f97"},"outputs":[],"source":["# [optional] load\n","qa_dataset = EmbeddingQAFinetuneDataset.from_json(\"pg_eval_dataset.json\")"]},{"cell_type":"markdown","id":"d3267fd6-187c-4e11-9f80-cfce08d98f1f","metadata":{"id":"d3267fd6-187c-4e11-9f80-cfce08d98f1f"},"source":["## Use `RetrieverEvaluator` for Retrieval Evaluation\n","\n","We're now ready to run our retrieval evals. We'll run our `RetrieverEvaluator` over the eval dataset that we generated."]},{"cell_type":"markdown","id":"16e56d17-2aa9-4e83-94ee-702088664b3c","metadata":{"id":"16e56d17-2aa9-4e83-94ee-702088664b3c"},"source":["We define two functions: `get_eval_results` and also `display_results` that run our retriever over the dataset."]},{"cell_type":"code","execution_count":null,"id":"17b870a4-095c-47b9-95b9-ae44cc0c014a","metadata":{"id":"17b870a4-095c-47b9-95b9-ae44cc0c014a"},"outputs":[],"source":["include_cohere_rerank = True\n","\n","if include_cohere_rerank:\n","    !pip install cohere -q"]},{"cell_type":"code","execution_count":null,"id":"42fa6f9c-a6da-43c4-b4c6-748ada393490","metadata":{"id":"42fa6f9c-a6da-43c4-b4c6-748ada393490"},"outputs":[],"source":["from llama_index.core.evaluation import RetrieverEvaluator\n","\n","metrics = [\"mrr\", \"hit_rate\"]\n","\n","if include_cohere_rerank:\n","    metrics.append(\n","        \"cohere_rerank_relevancy\"  # requires COHERE_API_KEY environment variable to be set\n","    )\n","\n","retriever_evaluator = RetrieverEvaluator.from_metric_names(\n","    metrics, retriever=retriever\n",")"]},{"cell_type":"code","execution_count":null,"id":"a16f3351-d745-46b3-b53b-916f7c244def","metadata":{"id":"a16f3351-d745-46b3-b53b-916f7c244def","outputId":"200ef6b1-1d53-404a-dc7a-1023529b0086"},"outputs":[{"name":"stdout","output_type":"stream","text":["Query: In the context provided, the author describes his early experiences with programming on an IBM 1401. Based on his description, what were some of the limitations and challenges he faced while trying to write programs on this machine?\n","Metrics: {'mrr': 1.0, 'hit_rate': 1.0, 'cohere_rerank_relevancy': 0.99620515}\n","\n"]}],"source":["# try it out on a sample query\n","sample_id, sample_query = list(qa_dataset.queries.items())[0]\n","sample_expected = qa_dataset.relevant_docs[sample_id]\n","\n","eval_result = retriever_evaluator.evaluate(sample_query, sample_expected)\n","print(eval_result)"]},{"cell_type":"code","execution_count":null,"id":"3963d146-c4a3-4b00-8b53-52c6ec03d862","metadata":{"id":"3963d146-c4a3-4b00-8b53-52c6ec03d862"},"outputs":[],"source":["# try it out on an entire dataset\n","eval_results = await retriever_evaluator.aevaluate_dataset(qa_dataset)"]},{"cell_type":"code","execution_count":null,"id":"ddbc38c7-660e-451b-8305-e8a7f23510a0","metadata":{"id":"ddbc38c7-660e-451b-8305-e8a7f23510a0"},"outputs":[],"source":["import pandas as pd\n","\n","\n","def display_results(name, eval_results):\n","    \"\"\"Display results from evaluate.\"\"\"\n","\n","    metric_dicts = []\n","    for eval_result in eval_results:\n","        metric_dict = eval_result.metric_vals_dict\n","        metric_dicts.append(metric_dict)\n","\n","    full_df = pd.DataFrame(metric_dicts)\n","\n","    hit_rate = full_df[\"hit_rate\"].mean()\n","    mrr = full_df[\"mrr\"].mean()\n","    columns = {\"retrievers\": [name], \"hit_rate\": [hit_rate], \"mrr\": [mrr]}\n","\n","    if include_cohere_rerank:\n","        crr_relevancy = full_df[\"cohere_rerank_relevancy\"].mean()\n","        columns.update({\"cohere_rerank_relevancy\": [crr_relevancy]})\n","\n","    metric_df = pd.DataFrame(columns)\n","\n","    return metric_df"]},{"cell_type":"code","execution_count":null,"id":"d059d5ee-d2aa-4edf-8b9b-e09d29ff17b2","metadata":{"id":"d059d5ee-d2aa-4edf-8b9b-e09d29ff17b2","outputId":"da5e7f7e-52d8-4755-ceb2-39e19861adbe"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>retrievers</th>\n","      <th>hit_rate</th>\n","      <th>mrr</th>\n","      <th>cohere_rerank_relevancy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>top-2 eval</td>\n","      <td>0.801724</td>\n","      <td>0.685345</td>\n","      <td>0.946009</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   retrievers  hit_rate       mrr  cohere_rerank_relevancy\n","0  top-2 eval  0.801724  0.685345                 0.946009"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["display_results(\"top-2 eval\", eval_results)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3"},"colab":{"provenance":[{"file_id":"https://github.com/run-llama/llama_index/blob/main/docs/docs/examples/evaluation/retrieval/retriever_eval.ipynb","timestamp":1717491965021}]}},"nbformat":4,"nbformat_minor":5}